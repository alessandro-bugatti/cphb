\chapter{Programmazione dinamica}

\index{programmazione dinamica}

La \key{programmazione dinamica}
è una tecnica che combina la correttezza della
ricerca completa con l'efficienza degli algoritmi
greedy.
La programmazione dinamica può essere
applicata nei casi in cui il problema da risolvere
può essere suddiviso in sottoproblemi
parzialmente sovrapposti e che possono
essere risolti in maniera indipendente.
La programmazione dinamica può essere utilizzata
in due casi:

\begin{itemize}
\item
\key{Trovare una soluzione ottimale}:
si vuole trovare una soluzione che è la
più grande o la più piccola possibile.
\item
\key{Contare il numero di soluzioni}:
si vuole calcolare il numero totale di 
soluzioni possibili.
\end{itemize}

Si vedrà prima come usare la programmazione
dinamica per trovare la soluzione ottima di un problema,
e poi la stessa idea verrà utilizzata per 
contare le soluzioni.

Comprendere come utilizzare la programmazione dinamica
è un momento cruciale nella carriera di ogni
programmatore che dedideri partecipare a delle gare algoritmiche.
Nonostante l'idea di base sia semplice,
la difficoltà risiede in come applicarla
in problemi anche molto differenti tra di loro.
Questo capitolo introduce un insieme di problemi classici 
che sono un buon punto di partenza.

\section{Problema delle monete}

Questo primo problema era già stato studiato 
nel capitolo 6: dato un insieme di monete di valori
$\texttt{coins} = \{c_1,c_2,\ldots,c_k\}$,
si vuole ottenere una somma
$n$ che utilizzi il minor numero di monete possibile.

Nel capitolo 6 il problema è stato risolto utilizzando
un algoritmo greedy che ad ogni passo sceglie 
la moneta più grande possibile.
L'algoritmo greedy funziona ad esempio se i valori delle
monete sono quelli degli euro,
ma nel caso generale con valori delle monete qualsiasi
non è detto produca il risultato ottimo.

Adesso si vedrà che utilizzando la
programmazione dinamica il problema 
potrà essere risolto in modo efficiente,
garantendo il risultato corretto 
per insiemi qualsiasi dei valori delle monete.
Questo algoritmo si basa su una formulazione
ricorsiva che esplora tutte le somme possibili,
come nell'approcio a forza bruta.
Però, a differenza di quest'ultimo, la versione
dinamica utilizza la \emph{memoizzazione} e calcola
la risposta a ogni sottoproblema una volta soltanto.

\subsubsection{Formulazione ricorsiva}

L'idea nella programmazione dinamica è quella di 
formulare il problema in forma ricorsiva
in modo che il problema possa essere 
risolto combinando le soluzioni di sottoproblemi
più piccoli.
Nel problema delle monete una formulazione
ricorsiva del problema è la seguente:
qual è il più piccolo numero di monete richiesto per 
formare una somma $x$?

Sia $\texttt{solve}(x)$
il minimo numero di monete richieste per 
formare una somma $x$. Il valore
della funzione dipende dai valori delle monete
che si hanno a disposizione.
Avendo come insieme $\texttt{coins} = \{1,3,4\}$,
i primi valori della funzione saranno:

\[
\begin{array}{lcl}
\texttt{solve}(0) & = & 0 \\
\texttt{solve}(1) & = & 1 \\
\texttt{solve}(2) & = & 2 \\
\texttt{solve}(3) & = & 1 \\
\texttt{solve}(4) & = & 1 \\
\texttt{solve}(5) & = & 2 \\
\texttt{solve}(6) & = & 2 \\
\texttt{solve}(7) & = & 2 \\
\texttt{solve}(8) & = & 2 \\
\texttt{solve}(9) & = & 3 \\
\texttt{solve}(10) & = & 3 \\
\end{array}
\]

Per esempio, $\texttt{solve}(10)=3$,
poichè servono almeno 3 monete per formare
la somma 10, che in questo caso sono $3+3+4=10$.

La proprietà essenziale delle funzione $\texttt{solve}$ 
è che i suoi valori possono essere calcolati
ricorsivamente a partire da valori più piccoli.

L'idea è di focalizzarsi sulla \emph{prima}
moneta che può essere scelta per la somma.
Nell'esempio mostrato la prima moneta 
potrebbe essere 1, 3 o 4.
Scegliendo come prima moneta quella di valore 1,
il problema diventa come formare la somma 9
usando il minor numero di monete,
che, come si vede, è un sottoproblema del problema originale.
Ovviamente lo stesso discorso si potrebbe applicare
alle monete di valore 3 e 4.
Quindi ne deriva la seguente formula ricorsiva per
il calcolo del minimo numero di monete:
\begin{equation*}
\begin{split}
\texttt{solve}(x) = \min( & \texttt{solve}(x-1)+1, \\
                           & \texttt{solve}(x-3)+1, \\
                           & \texttt{solve}(x-4)+1).
\end{split}
\end{equation*}
Il caso base della ricorsione è $\texttt{solve}(0)=0$,
perchè per formare la somma 0 non sono necessarie monete.
Per esempio
\[ \texttt{solve}(10) = \texttt{solve}(7)+1 = \texttt{solve}(4)+2 = \texttt{solve}(0)+3 = 3.\]

Una volta compreso il meccanismo è possibile dare una forma
generale alla funzione ricorsiva che calcola il minimo
numero di monete necessarie a formare una somma $x$:
\begin{equation*}
    \texttt{solve}(x) = \begin{cases}
               \infty               & x < 0\\
               0               & x = 0\\
               \min_{c \in \texttt{coins}} \texttt{solve}(x-c)+1 & x > 0 \\
           \end{cases}
\end{equation*}

Se $x<0$, il valore è $\infty$,
poichè è impossibile creare una somma negativa
a partire da monete di valore positivo.
Se invece $x=0$, il valore è $0$,
poichè, come detto in precedenza,
non sono necessarie monete per formare
una somma vuota.
Infine, se $x>0$,
la variabile $c$, che rappresenta la prima moneta scelta,
assume tutti i valori possibili 
delle monete e verrà poi scelta ricorsivamente 
quella che minimizza il numero di monete.

Una volta definita la funzione ricorsiva che risolve il problema,
può essere direttamente implementata in C++
(la costante \texttt{INF} rappresenta l'infinito):

\begin{lstlisting}
int solve(int x) {
    if (x < 0) return INF;
    if (x == 0) return 0;
    int best = INF;
    for (auto c : coins) {
        best = min(best, solve(x-c)+1);
    }
    return best;
}
\end{lstlisting}

Comunque, implementata in questo modo,
la funzione non è efficiente,
poichè c'è un numero esponenziale
di modi di costruire questa somma.
Si vedrà adesso come renderla efficiente
utilizzando una tecnica chiamata \emph{memoizzazione}\footnote{Per il lettore italiano: 
il termine memoizzazione non va confuso con memorizzazione. Nell'originale inglese non c'è
questo pericolo perchè i due termini vengono resi con \emph{memoization} e \emph{store}, nella 
traduzione italiana è stata usata \emph{memoizzazione} per 
riferirsi alla tecnica e \emph{memorizzazione} quando un
valore viene memorizzato in memoria.}.

\subsubsection{Usare la memoizzazione}

\index{memoizzazione}

L'idea base della programmazione dinamica è quella
di usare la \key{memoizzazione} 
per calcolare i valori di una funzione ricorsiva
in maniera efficiente.
Questo si ottiene memorizzando i valori della funzione
in un array (eventualmente multidimensionale) dopo che sono stati calcolati la prima volta.
In questo modo, per ogni parametro, il valore della funzione viene calcolato
ricorsivamente una sola volta, dopodichè può essere
recuperato dall'array.

Nel problema delle monete si potrebbero utilizzare
questi due array:

\begin{lstlisting}
bool ready[N];
int value[N];
\end{lstlisting}

dove $\texttt{ready}[x]$ indica se il valore di
$\texttt{solve}(x)$ è stato calcolato,
e se lo è $\texttt{value}[x]$
ne contiene il valore.
La costante $N$ deve essere scelta in modo tale
che gli array possano contenere tutti i valori necessari.

A questo punto un'implementazione efficiente
può essere scritta in questo modo:

\begin{lstlisting}
int solve(int x) {
    if (x < 0) return INF;
    if (x == 0) return 0;
    if (ready[x]) return value[x];
    int best = INF;
    for (auto c : coins) {
        best = min(best, solve(x-c)+1);
    }
    value[x] = best;
    ready[x] = true;
    return best;
}
\end{lstlisting}

I casi base $x<0$ e $x=0$ sono gestiti come prima,
poi la funzione controlla attraverso il valore di 
$\texttt{ready}[x]$ se
$\texttt{solve}(x)$ già stato calcolato in precedenza
e memorizzato in $\texttt{value}[x]$ e se lo è
viene direttamente ritornato.
Altrimenti la funzione calcola il valore
$\texttt{solve}(x)$ ricorsivamente e lo memorizza 
in $\texttt{value}[x]$.

In questo modo la funzione diventa efficiente,
poichè la risposta per ogni valore del parametro $x$
è calcolata ricorsivamente una volta soltanto e successivamente
quel valore può essere recuperato in $O(1)$ attraverso
l'utilizzo dell'array $\texttt{value}$.
La complessità computazionale dell'algoritmo diventa quindi $O(nk)$,
dove $n$ è la somma da ottenere e $k$ è il numero di monete.

Si può notare che sarebbe possibile 
costruire l'array \texttt{value} \emph{iterativamente}
usando un ciclo che semplicemente calcola tutti i 
valori di $\texttt{solve}$ per i parametri $0 \ldots n$:
\begin{lstlisting}
value[0] = 0;
for (int x = 1; x <= n; x++) {
    value[x] = INF;
    for (auto c : coins) {
        if (x-c >= 0) {
            value[x] = min(value[x], value[x-c]+1);
        }
    }
}
\end{lstlisting}

Nelle competizioni di alto livello, i programmatori
più abili preferiscono questa seconda implementazione,
poichè è più corta da scrivere e ha dei costi costanti più bassi
(pur avendo la stessa complessità computazionale),
quindi nei prossimi esempi verrà usata
questa tipo di implementazione ricorsiva.
Comunque è spesso più semplice applicare
la programmazione dinamica partendo 
da una funzione ricorsiva.

\subsubsection{Costruzione di una soluzione}

In alcuni problemi può essere richiesto sia
di trovare il valore della soluzione ottima
che di mostrare un modo per ottenere quella soluzione.

Nel problema delle monete, ad esempio, è possibile
dichiarare un altro array che indica per ogni
somma di monete la prima moneta che appartiene a 
una soluzione ottimale:
\begin{lstlisting}
int first[N];
\end{lstlisting}
L'algoritmo può quindi essere modificato nel seguente modo:
\begin{lstlisting}
value[0] = 0;
for (int x = 1; x <= n; x++) {
    value[x] = INF;
    for (auto c : coins) {
        if (x-c >= 0 && value[x-c]+1 < value[x]) {
            value[x] = value[x-c]+1;
            first[x] = c;
        }
    }
}
\end{lstlisting}
Facendo così e utilizzando il vettore \textit{first}, è
possibile stampare le monete che appaiono in una soluzione ottima
per la somma $x$:
\begin{lstlisting}
while (n > 0) {
    cout << first[n] << "\n";
    n -= first[n];
}
\end{lstlisting}

\subsubsection{Contare il numero di soluzioni}

Si consideri un'altra versione del problema delle monete,
nella quale lo scopo sia quello di calcolare
il numero totale di modi in cui possa essere 
ottenuta la somma $n$ usando le monete date.
Per esempio, se $\texttt{coins}=\{1,3,4\}$ e
$x=5$, ci sono in totale 6 differenti modi per ottenere la somma richiesta:

\begin{multicols}{2}
\begin{itemize}
\item $1+1+1+1+1$
\item $1+1+3$
\item $1+3+1$
\item $3+1+1$
\item $1+4$
\item $4+1$
\end{itemize}
\end{multicols}

Anche in questo caso il problema può essere risolto ricorsivamente.
Sia $\texttt{solve}(x)$ il numero di modi differenti in cui può
essere formata la somma $x$.
Nell'esempio precedente in cui $\texttt{coins}=\{1,3,4\}$,
allora $\texttt{solve}(5)=6$ e la formula ricorsiva risulta essere:
\begin{equation*}
\begin{split}
\texttt{solve}(x) = & \texttt{solve}(x-1) + \\
                    & \texttt{solve}(x-3) + \\
                    & \texttt{solve}(x-4)  .
\end{split}
\end{equation*}

Quindi la versione generale di questa formula diventa:
\begin{equation*}
    \texttt{solve}(x) = \begin{cases}
               0               & x < 0\\
               1               & x = 0\\
               \sum_{c \in \texttt{coins}} \texttt{solve}(x-c) & x > 0 \\
           \end{cases}
\end{equation*}

Se $x<0$, allora il valore è 0, perchè non ci sono soluzioni.
Se $x=0$, il valore è 1 perchè esiste un solo modo 
per creare la somma vuota.
Altrimenti bisogna calcolare la somma di tutti i valori
della forma $\texttt{solve}(x-c)$ con $c$ contenuto in \texttt{coins}.

Il seguente codice costruisce un array
$\texttt{count}$ tale che
$\texttt{count}[x]$ sia uguale al valore di $\texttt{solve}(x)$
per $0 \le x \le n$:

\begin{lstlisting}
count[0] = 1;
for (int x = 1; x <= n; x++) {
    for (auto c : coins) {
        if (x-c >= 0) {
            count[x] += count[x-c];
        }
    }
}
\end{lstlisting}

Spesso il numero di soluzioni è talmente grande
che non viene richiesto di calcolare il numero esatto, 
ma semplicemente di dare la risposta modulo $m$,
con $m$ ad esempio uguale a $10^9+7$.
Per ottenere questo risultato è sufficiente 
cambiare il codice in modo che tutti i calcoli siano fatti modulo $m$.
Quindi basta aggiungere la linea
\begin{lstlisting}
        count[x] %= m;
\end{lstlisting}
dopo la linea
\begin{lstlisting}
        count[x] += count[x-c];
\end{lstlisting}

Fino a questo punto sono state discusse tutte 
le idee base della programmazione dinamica.
Siccome la programmazione dinamica può essere
usata in un range molto ampio di problemi,
verranno adesso mostrati degli esempi classici,
in modo da comprenderne meglio il funzionamento.

\section{La più lunga sottosequenza crescente}

\index{più lunga sottosequenza crescente}

Il primo problema che verrà esposto è 
quello di trovare la \key{più lunga sottosequenza crescente}
all'interno di un array di $n$ elementi.
Tale sottosequenza è quella con più
elementi, non necessariamente consecutivi, da sinistra a destra,
in cui ogni elemento è più grande del precedente.
Per esempio, nell'array

\begin{center}
\begin{tikzpicture}[scale=0.7]
\draw (0,0) grid (8,1);
\node at (0.5,0.5) {$6$};
\node at (1.5,0.5) {$2$};
\node at (2.5,0.5) {$5$};
\node at (3.5,0.5) {$1$};
\node at (4.5,0.5) {$7$};
\node at (5.5,0.5) {$4$};
\node at (6.5,0.5) {$8$};
\node at (7.5,0.5) {$3$};

\footnotesize
\node at (0.5,1.4) {$0$};
\node at (1.5,1.4) {$1$};
\node at (2.5,1.4) {$2$};
\node at (3.5,1.4) {$3$};
\node at (4.5,1.4) {$4$};
\node at (5.5,1.4) {$5$};
\node at (6.5,1.4) {$6$};
\node at (7.5,1.4) {$7$};
\end{tikzpicture}
\end{center}
la più lunga sottosequenza crescente 
contiene 4 elementi:
\begin{center}
\begin{tikzpicture}[scale=0.7]
\fill[color=lightgray] (1,0) rectangle (2,1);
\fill[color=lightgray] (2,0) rectangle (3,1);
\fill[color=lightgray] (4,0) rectangle (5,1);
\fill[color=lightgray] (6,0) rectangle (7,1);
\draw (0,0) grid (8,1);
\node at (0.5,0.5) {$6$};
\node at (1.5,0.5) {$2$};
\node at (2.5,0.5) {$5$};
\node at (3.5,0.5) {$1$};
\node at (4.5,0.5) {$7$};
\node at (5.5,0.5) {$4$};
\node at (6.5,0.5) {$8$};
\node at (7.5,0.5) {$3$};

\draw[thick,->] (1.5,-0.25) .. controls (1.75,-1.00) and (2.25,-1.00) .. (2.4,-0.25);
\draw[thick,->] (2.6,-0.25) .. controls (3.0,-1.00) and (4.0,-1.00) .. (4.4,-0.25);
\draw[thick,->] (4.6,-0.25) .. controls (5.0,-1.00) and (6.0,-1.00) .. (6.5,-0.25);

\footnotesize
\node at (0.5,1.4) {$0$};
\node at (1.5,1.4) {$1$};
\node at (2.5,1.4) {$2$};
\node at (3.5,1.4) {$3$};
\node at (4.5,1.4) {$4$};
\node at (5.5,1.4) {$5$};
\node at (6.5,1.4) {$6$};
\node at (7.5,1.4) {$7$};
\end{tikzpicture}
\end{center}

Sia $\texttt{length}(k)$ la lunghezza della
più lunga sottosequenza che termina in posizione $k$.
Quindi calcolando tutti i valori di
$\texttt{length}(k)$ con $0 \le k \le n-1$,
si troverà la lunghezza della più lunga sottosequenza
per il vettore di lunghezza $n$.
Ad esempio, i valori di questa funzione 
per l'array visto in precedenza sono i seguenti:
\[
\begin{array}{lcl}
\texttt{length}(0) & = & 1 \\
\texttt{length}(1) & = & 1 \\
\texttt{length}(2) & = & 2 \\
\texttt{length}(3) & = & 1 \\
\texttt{length}(4) & = & 3 \\
\texttt{length}(5) & = & 2 \\
\texttt{length}(6) & = & 4 \\
\texttt{length}(7) & = & 2 \\
\end{array}
\]

Considerando ad esempio il caso $\texttt{length}(6)=4$,
il valore risulta 4 poichè la più lunga sottosequenza che
finisce alla posizione 6 consiste di 4 elementi. Invece per il caso $k=5$
è 2 perchè la più lunga sottosequenza che finisce in posizione 5 può essere
solo {2, 4} oppure {1, 4}, che sono entrambe di lunghezza 2.

Per calcolare il valore di $\texttt{length}(k)$,
è necessario trovare una posizione $i<k$
per la quale $\texttt{array}[i]<\texttt{array}[k]$
e $\texttt{length}(i)$ abbia il maggior valore possibile.
A questo punto il valore di $\texttt{length}(k)$ 
sarà $\texttt{length}(k)=\texttt{length}(i)+1$,
poichè questo è il modo ottimale di aggiungere
$\texttt{array}[k]$ alla sottosequenza.
Se invece non fosse possibile trovare una posizione $i$
per cui valgano le condizioni descritte in precedenza,
allora sarà $\texttt{length}(k)=1$,
il che significa che la sequenza contiene solo
$\texttt{array}[k]$.

Dal momento che tutti i valori della funzione possono essere
calcolati a partire da valori più piccoli,
è possibile usare la programmazione dinamica.
Nel codice seguente i valori della funzione
vengono memorizzati nell'array
$\texttt{length}$.

\begin{lstlisting}
for (int k = 0; k < n; k++) {
    length[k] = 1;
    for (int i = 0; i < k; i++) {
        if (array[i] < array[k]) {
            length[k] = max(length[k],length[i]+1);
        }
    }
}
\end{lstlisting}

Questo algoritmo è di classe $O(n^2)$,
poichè è composto da due cicli annidati.
Si può comunque verificare che è possibile 
implementarlo in modo più efficiente, 
riducendolo a un algoritmo di complessità $O(n \log n)$.
Viene lasciato al lettore come esercizio di trovare il modo di farlo.

\section{Paths in a grid}

Our next problem is to find a path
from the upper-left corner to
the lower-right corner
of an $n \times n$ grid, such that
we only move down and right.
Each square contains a positive integer,
and the path should be constructed so
that the sum of the values along
the path is as large as possible.

The following picture shows an optimal
path in a grid:
\begin{center}
\begin{tikzpicture}[scale=.65]
  \begin{scope}
    \fill [color=lightgray] (0, 9) rectangle (1, 8);
    \fill [color=lightgray] (0, 8) rectangle (1, 7);
    \fill [color=lightgray] (1, 8) rectangle (2, 7);
    \fill [color=lightgray] (1, 7) rectangle (2, 6);
    \fill [color=lightgray] (2, 7) rectangle (3, 6);
    \fill [color=lightgray] (3, 7) rectangle (4, 6);
    \fill [color=lightgray] (4, 7) rectangle (5, 6);
    \fill [color=lightgray] (4, 6) rectangle (5, 5);
    \fill [color=lightgray] (4, 5) rectangle (5, 4);
    \draw (0, 4) grid (5, 9);
    \node at (0.5,8.5) {3};
    \node at (1.5,8.5) {7};
    \node at (2.5,8.5) {9};
    \node at (3.5,8.5) {2};
    \node at (4.5,8.5) {7};
    \node at (0.5,7.5) {9};
    \node at (1.5,7.5) {8};
    \node at (2.5,7.5) {3};
    \node at (3.5,7.5) {5};
    \node at (4.5,7.5) {5};
    \node at (0.5,6.5) {1};
    \node at (1.5,6.5) {7};
    \node at (2.5,6.5) {9};
    \node at (3.5,6.5) {8};
    \node at (4.5,6.5) {5};
    \node at (0.5,5.5) {3};
    \node at (1.5,5.5) {8};
    \node at (2.5,5.5) {6};
    \node at (3.5,5.5) {4};
    \node at (4.5,5.5) {10};
    \node at (0.5,4.5) {6};
    \node at (1.5,4.5) {3};
    \node at (2.5,4.5) {9};
    \node at (3.5,4.5) {7};
    \node at (4.5,4.5) {8};
  \end{scope}
\end{tikzpicture}
\end{center}
The sum of the values on the path is 67,
and this is the largest possible sum on a path
from the
upper-left corner to the lower-right corner.

Assume that the rows and columns of the
grid are numbered from 1 to $n$,
and $\texttt{value}[y][x]$ equals the value
of square $(y,x)$.
Let $\texttt{sum}(y,x)$ denote the maximum
sum on a path from the upper-left corner
to square $(y,x)$.
Now $\texttt{sum}(n,n)$ tells us
the maximum sum
from the upper-left corner to
the lower-right corner.
For example, in the above grid,
$\texttt{sum}(5,5)=67$.

We can recursively calculate the sums
as follows:
\[ \texttt{sum}(y,x) = \max(\texttt{sum}(y,x-1),\texttt{sum}(y-1,x))+\texttt{value}[y][x]\]


The recursive formula is based on the observation
that a path that ends at square $(y,x)$
can come either from square $(y,x-1)$
or square $(y-1,x)$:
\begin{center}
\begin{tikzpicture}[scale=.65]
  \begin{scope}
    \fill [color=lightgray] (3, 7) rectangle (4, 6);
    \draw (0, 4) grid (5, 9);
    
    \node at (2.5,6.5) {$\rightarrow$};
    \node at (3.5,7.5) {$\downarrow$};
    
  \end{scope}
\end{tikzpicture}
\end{center}

Thus, we select the direction that maximizes
the sum.
We assume that $\texttt{sum}(y,x)=0$
if $y=0$ or $x=0$ (because no such paths exist),
so the recursive formula also works when $y=1$ or $x=1$.

Since the function \texttt{sum} has two parameters,
the dynamic programming array also has two dimensions.
For example, we can use an array
\begin{lstlisting}
int sum[N][N];
\end{lstlisting}
and calculate the sums as follows:
\begin{lstlisting}
for (int y = 1; y <= n; y++) {
    for (int x = 1; x <= n; x++) {
        sum[y][x] = max(sum[y][x-1],sum[y-1][x])+value[y][x];
    }
}
\end{lstlisting}
The time complexity of the algorithm is $O(n^2)$.

\section{Knapsack problems}

\index{knapsack}

The term \key{knapsack} refers to problems where
a set of objects is given, and 
subsets with some properties
have to be found.
Knapsack problems can often be solved
using dynamic programming.

In this section, we focus on the following
problem: Given a list of weights
$[w_1,w_2,\ldots,w_n]$,
determine all
sums that can be constructed using the weights.
For example, if the weights are
$[1,3,3,5]$, the following sums are possible:

\begin{center}
\begin{tabular}{rrrrrrrrrrrrr}
 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\
\hline
 X & X & & X & X & X & X & X & X & X & & X & X \\
\end{tabular}
\end{center}

In this case, all sums between $0 \ldots 12$
are possible, except 2 and 10.
For example, the sum 7 is possible because we
can select the weights $[1,3,3]$.

To solve the problem, we focus on subproblems
where we only use the first $k$ weights
to construct sums.
Let $\texttt{possible}(x,k)=\textrm{true}$ if
we can construct a sum $x$
using the first $k$ weights,
and otherwise $\texttt{possible}(x,k)=\textrm{false}$.
The values of the function can be recursively
calculated as follows:
\[ \texttt{possible}(x,k) = \texttt{possible}(x-w_k,k-1) \lor \texttt{possible}(x,k-1) \]
The formula is based on the fact that we can
either use or not use the weight $w_k$ in the sum.
If we use $w_k$, the remaining task is to
form the sum $x-w_k$ using the first $k-1$ weights,
and if we do not use $w_k$,
the remaining task is to form the sum $x$
using the first $k-1$ weights.
As the base cases,
\begin{equation*}
    \texttt{possible}(x,0) = \begin{cases}
               \textrm{true}    & x = 0\\
               \textrm{false}   & x \neq 0 \\
           \end{cases}
\end{equation*}
because if no weights are used,
we can only form the sum 0.

The following table shows all values of the function
for the weights $[1,3,3,5]$ (the symbol ''X''
indicates the true values):

\begin{center}
\begin{tabular}{r|rrrrrrrrrrrrr}
$k \backslash x$ & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\
\hline
 0 & X & \\
 1 & X & X \\
 2 & X & X & & X & X \\
 3 & X & X & & X & X & & X & X \\
 4 & X & X & & X & X & X & X & X & X & X & & X & X \\
\end{tabular}
\end{center}

After calculating those values, $\texttt{possible}(x,n)$
tells us whether we can construct a
sum $x$ using \emph{all} weights.

Let $W$ denote the total sum of the weights.
The following $O(nW)$ time
dynamic programming solution
corresponds to the recursive function:
\begin{lstlisting}
possible[0][0] = true;
for (int k = 1; k <= n; k++) {
    for (int x = 0; x <= W; x++) {
        if (x-w[k] >= 0) possible[x][k] |= possible[x-w[k]][k-1];
        possible[x][k] |= possible[x][k-1];
    }
}
\end{lstlisting}

However, here is a better implementation that only uses
a one-dimensional array $\texttt{possible}[x]$
that indicates whether we can construct a subset with sum $x$.
The trick is to update the array from right to left for
each new weight:
\begin{lstlisting}
possible[0] = true;
for (int k = 1; k <= n; k++) {
    for (int x = W; x >= 0; x--) {
        if (possible[x]) possible[x+w[k]] = true;
    }
}
\end{lstlisting}

Note that the general idea presented here can be used
in many knapsack problems.
For example, if we are given objects with weights and values,
we can determine for each weight sum the maximum value
sum of a subset.

\section{Edit distance}

\index{edit distance}
\index{Levenshtein distance}

The \key{edit distance} or \key{Levenshtein distance}\footnote{The distance
is named after V. I. Levenshtein who studied it in connection with binary codes \cite{lev66}.}
is the minimum number of editing operations
needed to transform a string
into another string.
The allowed editing operations are as follows:
\begin{itemize}
\item insert a character (e.g. \texttt{ABC} $\rightarrow$ \texttt{ABCA})
\item remove a character (e.g. \texttt{ABC} $\rightarrow$ \texttt{AC})
\item modify a character (e.g. \texttt{ABC} $\rightarrow$ \texttt{ADC})
\end{itemize}

For example, the edit distance between
\texttt{LOVE} and \texttt{MOVIE} is 2,
because we can first perform the operation
 \texttt{LOVE} $\rightarrow$ \texttt{MOVE}
(modify) and then the operation
\texttt{MOVE} $\rightarrow$ \texttt{MOVIE}
(insert).
This is the smallest possible number of operations,
because it is clear that only one operation is not enough.

Suppose that we are given a string \texttt{x}
of length $n$ and a string \texttt{y} of length $m$,
and we want to calculate the edit distance between
\texttt{x} and \texttt{y}.
To solve the problem, we define a function
$\texttt{distance}(a,b)$ that gives the
edit distance between prefixes
$\texttt{x}[0 \ldots a]$ and $\texttt{y}[0 \ldots b]$.
Thus, using this function, the edit distance
between \texttt{x} and \texttt{y} equals $\texttt{distance}(n-1,m-1)$.

We can calculate values of \texttt{distance}
as follows:
\begin{equation*}
\begin{split}
\texttt{distance}(a,b) = \min(& \texttt{distance}(a,b-1)+1, \\
                           & \texttt{distance}(a-1,b)+1, \\
                           & \texttt{distance}(a-1,b-1)+\texttt{cost}(a,b)).
\end{split}
\end{equation*}
Here $\texttt{cost}(a,b)=0$ if $\texttt{x}[a]=\texttt{y}[b]$,
and otherwise $\texttt{cost}(a,b)=1$.
The formula considers the following ways to
edit the string \texttt{x}:
\begin{itemize}
\item $\texttt{distance}(a,b-1)$: insert a character at the end of \texttt{x}
\item $\texttt{distance}(a-1,b)$: remove the last character from \texttt{x}
\item $\texttt{distance}(a-1,b-1)$: match or modify the last character of \texttt{x}
\end{itemize}
In the two first cases, one editing operation is needed
(insert or remove).
In the last case, if $\texttt{x}[a]=\texttt{y}[b]$,
we can match the last characters without editing,
and otherwise one editing operation is needed (modify).

The following table shows the values of \texttt{distance}
in the example case:
\begin{center}
\begin{tikzpicture}[scale=.65]
  \begin{scope}
    %\fill [color=lightgray] (5, -3) rectangle (6, -4);
    \draw (1, -1) grid (7, -6);
    
    \node at (0.5,-2.5) {\texttt{L}};
    \node at (0.5,-3.5) {\texttt{O}};
    \node at (0.5,-4.5) {\texttt{V}};
    \node at (0.5,-5.5) {\texttt{E}};

    \node at (2.5,-0.5) {\texttt{M}};
    \node at (3.5,-0.5) {\texttt{O}};
    \node at (4.5,-0.5) {\texttt{V}};
    \node at (5.5,-0.5) {\texttt{I}};
    \node at (6.5,-0.5) {\texttt{E}};

    \node at (1.5,-1.5) {$0$};
    \node at (1.5,-2.5) {$1$};
    \node at (1.5,-3.5) {$2$};
    \node at (1.5,-4.5) {$3$};
    \node at (1.5,-5.5) {$4$};
    \node at (2.5,-1.5) {$1$};
    \node at (2.5,-2.5) {$1$};
    \node at (2.5,-3.5) {$2$};
    \node at (2.5,-4.5) {$3$};
    \node at (2.5,-5.5) {$4$};
    \node at (3.5,-1.5) {$2$};
    \node at (3.5,-2.5) {$2$};
    \node at (3.5,-3.5) {$1$};
    \node at (3.5,-4.5) {$2$};
    \node at (3.5,-5.5) {$3$};
    \node at (4.5,-1.5) {$3$};
    \node at (4.5,-2.5) {$3$};
    \node at (4.5,-3.5) {$2$};
    \node at (4.5,-4.5) {$1$};
    \node at (4.5,-5.5) {$2$};
    \node at (5.5,-1.5) {$4$};
    \node at (5.5,-2.5) {$4$};
    \node at (5.5,-3.5) {$3$};
    \node at (5.5,-4.5) {$2$};
    \node at (5.5,-5.5) {$2$};
    \node at (6.5,-1.5) {$5$};
    \node at (6.5,-2.5) {$5$};
    \node at (6.5,-3.5) {$4$};
    \node at (6.5,-4.5) {$3$};
    \node at (6.5,-5.5) {$2$};
  \end{scope}
\end{tikzpicture}
\end{center}

The lower-right corner of the table
tells us that the edit distance between
\texttt{LOVE} and \texttt{MOVIE} is 2.
The table also shows how to construct
the shortest sequence of editing operations.
In this case the path is as follows:

\begin{center}
\begin{tikzpicture}[scale=.65]
  \begin{scope}
    \draw (1, -1) grid (7, -6);
    
    \node at (0.5,-2.5) {\texttt{L}};
    \node at (0.5,-3.5) {\texttt{O}};
    \node at (0.5,-4.5) {\texttt{V}};
    \node at (0.5,-5.5) {\texttt{E}};

    \node at (2.5,-0.5) {\texttt{M}};
    \node at (3.5,-0.5) {\texttt{O}};
    \node at (4.5,-0.5) {\texttt{V}};
    \node at (5.5,-0.5) {\texttt{I}};
    \node at (6.5,-0.5) {\texttt{E}};

    \node at (1.5,-1.5) {$0$};
    \node at (1.5,-2.5) {$1$};
    \node at (1.5,-3.5) {$2$};
    \node at (1.5,-4.5) {$3$};
    \node at (1.5,-5.5) {$4$};
    \node at (2.5,-1.5) {$1$};
    \node at (2.5,-2.5) {$1$};
    \node at (2.5,-3.5) {$2$};
    \node at (2.5,-4.5) {$3$};
    \node at (2.5,-5.5) {$4$};
    \node at (3.5,-1.5) {$2$};
    \node at (3.5,-2.5) {$2$};
    \node at (3.5,-3.5) {$1$};
    \node at (3.5,-4.5) {$2$};
    \node at (3.5,-5.5) {$3$};
    \node at (4.5,-1.5) {$3$};
    \node at (4.5,-2.5) {$3$};
    \node at (4.5,-3.5) {$2$};
    \node at (4.5,-4.5) {$1$};
    \node at (4.5,-5.5) {$2$};
    \node at (5.5,-1.5) {$4$};
    \node at (5.5,-2.5) {$4$};
    \node at (5.5,-3.5) {$3$};
    \node at (5.5,-4.5) {$2$};
    \node at (5.5,-5.5) {$2$};
    \node at (6.5,-1.5) {$5$};
    \node at (6.5,-2.5) {$5$};
    \node at (6.5,-3.5) {$4$};
    \node at (6.5,-4.5) {$3$};
    \node at (6.5,-5.5) {$2$};

    \path[draw=red,thick,-,line width=2pt] (6.5,-5.5) -- (5.5,-4.5);
    \path[draw=red,thick,-,line width=2pt] (5.5,-4.5) -- (4.5,-4.5);
    \path[draw=red,thick,->,line width=2pt] (4.5,-4.5) -- (1.5,-1.5);
  \end{scope}
\end{tikzpicture}
\end{center}

The last characters of \texttt{LOVE} and \texttt{MOVIE}
are equal, so the edit distance between them
equals the edit distance between \texttt{LOV} and \texttt{MOVI}.
We can use one editing operation to remove the
character \texttt{I} from \texttt{MOVI}.
Thus, the edit distance is one larger than
the edit distance between \texttt{LOV} and \texttt{MOV}, etc.

\section{Counting tilings}

Sometimes the states of a dynamic programming solution
are more complex than fixed combinations of numbers.
As an example,
consider the problem of calculating
the number of distinct ways to
fill an $n \times m$ grid using
$1 \times 2$ and $2 \times 1$ size tiles.
For example, one valid solution
for the $4 \times 7$ grid is
\begin{center}
\begin{tikzpicture}[scale=.65]
    \draw (0,0) grid (7,4);
    \draw[fill=gray] (0+0.2,0+0.2) rectangle (2-0.2,1-0.2);
    \draw[fill=gray] (2+0.2,0+0.2) rectangle (4-0.2,1-0.2);
    \draw[fill=gray] (4+0.2,0+0.2) rectangle (6-0.2,1-0.2);
    \draw[fill=gray] (0+0.2,1+0.2) rectangle (2-0.2,2-0.2);
    \draw[fill=gray] (2+0.2,1+0.2) rectangle (4-0.2,2-0.2);
    \draw[fill=gray] (1+0.2,2+0.2) rectangle (3-0.2,3-0.2);
    \draw[fill=gray] (1+0.2,3+0.2) rectangle (3-0.2,4-0.2);
    \draw[fill=gray] (4+0.2,3+0.2) rectangle (6-0.2,4-0.2);

    \draw[fill=gray] (0+0.2,2+0.2) rectangle (1-0.2,4-0.2);
    \draw[fill=gray] (3+0.2,2+0.2) rectangle (4-0.2,4-0.2);
    \draw[fill=gray] (6+0.2,2+0.2) rectangle (7-0.2,4-0.2);
    \draw[fill=gray] (4+0.2,1+0.2) rectangle (5-0.2,3-0.2);
    \draw[fill=gray] (5+0.2,1+0.2) rectangle (6-0.2,3-0.2);
    \draw[fill=gray] (6+0.2,0+0.2) rectangle (7-0.2,2-0.2);

\end{tikzpicture}
\end{center}
and the total number of solutions is 781.

The problem can be solved using dynamic programming
by going through the grid row by row.
Each row in a solution can be represented as a
string that contains $m$ characters from the set
$\{\sqcap, \sqcup, \sqsubset, \sqsupset \}$.
For example, the above solution consists of four rows
that correspond to the following strings:
\begin{itemize}
\item
$\sqcap \sqsubset \sqsupset \sqcap \sqsubset \sqsupset \sqcap$
\item
$\sqcup \sqsubset \sqsupset \sqcup \sqcap \sqcap \sqcup$
\item
$\sqsubset \sqsupset \sqsubset \sqsupset \sqcup \sqcup \sqcap$ 
\item
$\sqsubset \sqsupset \sqsubset \sqsupset \sqsubset \sqsupset \sqcup$
\end{itemize}

Let $\texttt{count}(k,x)$ denote the number of ways to
construct a solution for rows $1 \ldots k$
of the grid such that string $x$ corresponds to row $k$.
It is possible to use dynamic programming here,
because the state of a row is constrained
only by the state of the previous row.

A solution is valid if row $1$ does not contain
the character $\sqcup$,
row $n$ does not contain the character $\sqcap$,
and all consecutive rows are \emph{compatible}.
For example, the rows
$\sqcup \sqsubset \sqsupset \sqcup \sqcap \sqcap \sqcup$ and
$\sqsubset \sqsupset \sqsubset \sqsupset \sqcup \sqcup \sqcap$ 
are compatible, while the rows
$\sqcap \sqsubset \sqsupset \sqcap \sqsubset \sqsupset \sqcap$ and
$\sqsubset \sqsupset \sqsubset \sqsupset \sqsubset \sqsupset \sqcup$
are not compatible.

Since a row consists of $m$ characters and there are
four choices for each character, the number of distinct
rows is at most $4^m$.
Thus, the time complexity of the solution is
$O(n 4^{2m})$ because we can go through the
$O(4^m)$ possible states for each row,
and for each state, there are $O(4^m)$
possible states for the previous row.
In practice, it is a good idea to rotate the grid
so that the shorter side has length $m$,
because the factor $4^{2m}$ dominates the time complexity.

It is possible to make the solution more efficient
by using a more compact representation for the rows.
It turns out that it is sufficient to know which
columns of the previous row contain the upper square
of a vertical tile.
Thus, we can represent a row using only characters
$\sqcap$ and $\Box$, where $\Box$ is a combination
of characters
$\sqcup$, $\sqsubset$ and $\sqsupset$.
Using this representation, there are only
$2^m$ distinct rows and the time complexity is
$O(n 2^{2m})$.

As a final note, there is also a surprising direct formula
for calculating the number of tilings\footnote{Surprisingly,
this formula was discovered in 1961 by two research teams \cite{kas61,tem61}
that worked independently.}:
\[ \prod_{a=1}^{\lceil n/2 \rceil} \prod_{b=1}^{\lceil m/2 \rceil} 4 \cdot (\cos^2 \frac{\pi a}{n + 1} + \cos^2 \frac{\pi b}{m+1})\]
This formula is very efficient, because it calculates
the number of tilings in $O(nm)$ time,
but since the answer is a product of real numbers,
a problem when using the formula is
how to store the intermediate results accurately.


